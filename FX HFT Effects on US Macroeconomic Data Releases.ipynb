{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883a0e92",
   "metadata": {},
   "source": [
    "# High-Frequency Effects and Modelling on FX Market in Response to US Macroeconomic Data Releases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b231d69",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "1. <span style=\"color:green\">Research and Planning\n",
    "    * Define clear research goals and objectives\n",
    "    * Decide on macroeconomic events and FX pairs</span>\n",
    "2. Literature Review\n",
    "    * Review past papers\n",
    "    * <span style=\"color:green\">Identify gaps (model that does stress testing, probability w/ price range, capturing retracement/correction)</span>\n",
    "3. Data Collection and Processing\n",
    "    *  <span style=\"color:green\">Identify data sources</span>\n",
    "    * <span style=\"color:green\">Collect FX pairs (date, minute interval, open, low, high, close)\n",
    "    * <span style=\"color:green\">Collect macroeconomic events (date, expected value, actual value)</span>\n",
    "    * <span style=\"color:green\">Merge datasets</span>\n",
    "    * <span style=\"color:green\">Keep only data with the macro events (not whole month but only on data releases)</span>\n",
    "    * Do some analysis for data dimensionality (e.g., analysis whether to keep 10 minutes before and 10 minutes after only of the data release)\n",
    "4. Exploratory Analysis\n",
    "    * Correlation of price movement with each macro event expected vs actual\n",
    "    * Feature importance (which macro event brings more volume)\n",
    "    * Variance after the events (volatility)\n",
    "5. <span style=\"color:orange\">Model Development\n",
    "    * Create some probabilistic TS model based on historical data\n",
    "6. <span style=\"color:orange\">Backtesting and Market Simulation\n",
    "    * KPIs and statistical measurement of model on test data (can be same as past)\n",
    "    * Create a class/function to take input of a pair, expected value of macro data, and minute after event to give some price range and classification with confidence interval\n",
    "7. <span style=\"color:orange\">Results and Discusion\n",
    "    * Interpret market reactions to economic data\n",
    "    * Compare model accuracy with benchmarks</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02014ad0",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25796743",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ee7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data fetching\n",
    "import yfinance as yf\n",
    "from polygon import RESTClient\n",
    "from fredapi import Fred\n",
    "\n",
    "# Libraries for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import time  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fb47d",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d2bbd",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Data Retrieval</span>\n",
    "* Data Collection FX pair tickers (symbols) for **Yahoo Finance**: \n",
    "    * **DXY** ðŸ † \"DX-Y.NYB\",\n",
    "    * **USD/GBP** ðŸ † \"GBPUSD=X\",\n",
    "    * **USD/EUR** ðŸ † \"EURUSD=X\",\n",
    "    * **USD/CNY** ðŸ † \"CNY=X\"\n",
    "\n",
    "\n",
    "* Data Collection FX pair tickers (symbols) for **Polygon.io**:\n",
    "    * **USD/EUR** ðŸ † C:USD/EUR\n",
    "    * **USD/GBP** ðŸ † C:USD/GBP\n",
    "    * **USD/CNY** ðŸ † C:USD/CHF\n",
    "    \n",
    "* Data Collection FX pair tickers (symbols) for **fred.stlouisfed.org**:\n",
    "    * **Inflation** ðŸ † CPIAUCSL\n",
    "    * **Interest Rates** ðŸ † FEDFUNDS\n",
    "    * **GDP** ðŸ † GDPC1\n",
    "    * **Unemployment Rate** ðŸ † UNRATE\n",
    "    * **PMI** ðŸ † NAPM\n",
    "    * **DXY** ðŸ † DTWEXBGS\n",
    "    \n",
    "* Macroeconomic events **Bloomberg Terminal (KCL)** (macro_data_bloomberg.csv):\n",
    "    * **INTR** (every 6-weeks)\n",
    "    * **CPI** (MoM)\n",
    "    * **GDP** (QoQ)\n",
    "    * **PCE** (MoM)\n",
    "    * **UNRATE** (MoM)\n",
    "    * **PMI** (MoM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0733297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_get_fx_data(fx_pair, interval, start_date, end_date, api_key='0GbCWQKVtPfEMJvPmc1n50psE3zsW1c8'):\n",
    "    \"\"\"\n",
    "    Retrieve historical FX data from Polygon.io.\n",
    "\n",
    "    Parameters:\n",
    "    - interval (str): The interval for the data ('1m', '5m', '1h', '1d').\n",
    "    - start_date (str): The start date in 'YYYY-MM-DD' format.\n",
    "    - end_date (str): The end date in 'YYYY-MM-DD' format.\n",
    "    - api_key (str): Polygon.io API key.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing historical USD/CNY forex data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Bring the fx pair ticker to Polygon's format\n",
    "        fx_pair_polygon_formated = \"C:\" + str(fx_pair)\n",
    "\n",
    "        client = RESTClient(api_key)\n",
    "\n",
    "        # Request data\n",
    "        data_request = client.get_aggs(\n",
    "            ticker=fx_pair_polygon_formated, \n",
    "            multiplier=1, \n",
    "            timespan=interval,\n",
    "            from_=start_date, \n",
    "            to=end_date\n",
    "        )\n",
    "    \n",
    "        # Convert response to DataFrame\n",
    "        df = pd.DataFrame(data_request)\n",
    "        \n",
    "        # Check if data is returned\n",
    "        if df.empty:\n",
    "            print(\"No data found.\")\n",
    "            return None\n",
    "\n",
    "        # Convert timestamp to datetime format and set Datetime as an index\n",
    "        df[\"Datetime\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "        df.set_index(\"Datetime\", inplace=True)\n",
    "        \n",
    "        # Drop columns not needed\n",
    "        df = df.drop(columns=[\"otc\", \"transactions\", \"timestamp\"])\n",
    "        \n",
    "        # Rename columns to align with yf for the feature engineering and merging later on\n",
    "        df = df.rename(columns={\"high\": \"High\", \"low\": \"Low\", \"close\": \"Adj Close\", \"volume\": \"Volume\"})\n",
    "        df = df.rename_axis(f'{fx_pair}', axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "        \n",
    "macro_df = pd.read_csv(\"macro_bloomberg_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700d944",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6754cd",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Data Preprocessing</span>\n",
    "1. Replace '--' to null\n",
    "2. DateTime format (some years to 2 digits some 4 e.g., 2025 and 25)\n",
    "3. Convert to DateTime\n",
    "4. Replace the % to decimals and convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf4fab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Finds for  '--' values and converts them to NaN. \n",
    "    Afterwards, drop rows where Expected and Actual are NaN.\n",
    "    \n",
    "    Parameters:\n",
    "    - df ()\n",
    "    \"\"\"\n",
    "    # Missing values convert from '--' to NaN\n",
    "    df.replace('--', np.nan, inplace=True)\n",
    "\n",
    "    # Drop rows where Expected and Actual are missing\n",
    "    df = macro_df.dropna(subset=[\"Expected\", \"Actual\"], how=\"all\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def standardize_datetime_format(df: pd.DataFrame, column_name=\"Date Time\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizes the Date Time column to the format MM/DD/YYYY HH:MM,\n",
    "    converts it to a datetime datatype, sets it as the index, and sorts the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the column to be formatted.\n",
    "    - column_name (str): The name of the column to standardize.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with the standardized datetime format, \n",
    "                    set as index, and sorted.\n",
    "    \"\"\"\n",
    "    def fix_date_format(date_str):\n",
    "        # Try parsing with two-digit year format first\n",
    "        dt = pd.to_datetime(date_str, format='%m/%d/%y %H:%M', errors='coerce')\n",
    "        \n",
    "        # If conversion fails, try four-digit year format\n",
    "        if pd.isnull(dt):\n",
    "            dt = pd.to_datetime(date_str, format='%m/%d/%Y %H:%M', errors='coerce')\n",
    "        \n",
    "        return dt  # Return as datetime object\n",
    "\n",
    "    # Apply the function to convert to datetime\n",
    "    df = df.copy(deep=True)\n",
    "    df[\"Datetime\"] = df[column_name].astype(str).apply(fix_date_format)\n",
    "    \n",
    "    # Drop rows where conversion failed\n",
    "    df = df.dropna(subset=[\"Datetime\"])\n",
    "    # Drop previous 'Date Time'\n",
    "    df.drop(columns=['Date Time'], inplace=True)\n",
    "\n",
    "    # Convert the column to datetime dtype\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"])\n",
    "\n",
    "    # Set Date Time as index\n",
    "    df = df.set_index(\"Datetime\")\n",
    "\n",
    "    # Sort DataFrame by the Date Time index\n",
    "    df = df.sort_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def convert_percentage_to_numeric(df: pd.DataFrame, columns=[\"Expected\", \"Actual\", \"Prior\"]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts percentage values in specified columns to numerical float values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing percentage values.\n",
    "    - columns (list): List of column names to convert.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with percentage values converted to floats.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str).str.replace('%', '', regex=True).astype(float)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def clean_macro_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drops the 'Event' column and renames 'Ticker' values to standardized names.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The macroeconomic DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Cleaned DataFrame with renamed tickers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop the 'Event' column\n",
    "    df = df.drop(columns=[\"Event\"], errors=\"ignore\")\n",
    "\n",
    "    # Dictionary mapping for renaming\n",
    "    ticker_mapping = {\n",
    "        \"UNRATE\": \"UNRATE\",\n",
    "        \"CPI_MoM\": \"CPI\",\n",
    "        \"INTR\": \"INTR\",\n",
    "        \"PCE_MoM\": \"PCE\",\n",
    "        \"GDP_QoQ\": \"GDP\",\n",
    "        \"PMI\": \"PMI\"\n",
    "    }\n",
    "\n",
    "    # Rename cols\n",
    "    df[\"Ticker\"] = df[\"Ticker\"].replace(ticker_mapping)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf88ff",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0439d3a",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Feature Engineering</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7fac11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprise_calculation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the surprise (difference) of Expected vs Actual.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): macro economic data\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Original dataframe plus the surprise column.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"Surprise\"] = df[\"Actual\"] - df[\"Expected\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_volatility(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the average volatility dynamically based on the number of rows in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): FX data.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The original DataFrame with added 'Volatility', \n",
    "                                                    'Average_Volatility', \n",
    "                                                    and 'Volatility_Multiplier' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        print(\"Error: DataFrame is empty or invalid.\")\n",
    "        return None\n",
    "    if \"Adj Close\" in df.columns:\n",
    "        # Compute Volatility\n",
    "        df['Volatility'] = np.abs(np.log(df['Adj Close'] / df['Adj Close'].shift(1)))\n",
    "    else:\n",
    "        df['Volatility'] = np.abs(np.log(df['Close'] / df['Close'].shift(1)))\n",
    "        \n",
    "    # Compute Average Volatility based on number of rows\n",
    "    df['Average_Volatility'] = df['Volatility'].mean()\n",
    "    # Compute Volatility Multiplier\n",
    "    df['Volatility_Multiplier'] = round(df['Volatility'] / df['Average_Volatility'],2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bf640",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99839827",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Plotting Functions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "288d3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(df, column):\n",
    "    \"\"\"\n",
    "    Plots a time series for a given data and column.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing time series data with a Datetime index.\n",
    "    - column (str): Column name to plot.\n",
    "    - title (str): Title of the plot (default: \"Time Series Plot\").\n",
    "\n",
    "    Returns:\n",
    "    - None (Displays the plot)\n",
    "    \"\"\"\n",
    "    \n",
    "    if column not in df.columns:\n",
    "        print(f\"Error: Column '{column}' not found in DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    fx_pair = df.columns.name if df.columns.name else \"FX Pair\"\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    df[column].plot(ax=ax)\n",
    "    \n",
    "    # Improve x-axis readability\n",
    "    ax.set_xlabel(\"Datetime\", fontsize=12)\n",
    "    ax.set_ylabel(column, fontsize=12)\n",
    "    ax.set_title(f\"'{fx_pair}' {column} Over Time\", fontsize=14)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Ensure the x-axis starts and ends exactly at the first and last data points (applicable only to yf data)\n",
    "    if \"vwap\" not in df.columns:\n",
    "        # Format x-axis to time\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax.set_xlim(df.index.min(), df.index.max())\n",
    "\n",
    "    ax.grid(True, which=\"major\", linestyle=\"-\", linewidth=0.6, alpha=1)  \n",
    "    ax.grid(True, which=\"minor\", linestyle=\"-\", linewidth=0.5, alpha=1) \n",
    "\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac884f",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977cbc4",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Macro data preprocessed</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "67db0ab6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Expected</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prior</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-10 13:30:00</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-14 13:30:00</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-29 19:00:00</th>\n",
       "      <td>INTR</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-30 13:30:00</th>\n",
       "      <td>GDP</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-31 13:30:00</th>\n",
       "      <td>PCE</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29 19:00:00</th>\n",
       "      <td>INTR</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-30 13:30:00</th>\n",
       "      <td>GDP</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-31 13:30:00</th>\n",
       "      <td>PCE</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07 13:30:00</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-12 13:30:00</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ticker  Expected  Actual  Prior  Surprise\n",
       "Datetime                                                      \n",
       "2020-01-10 13:30:00  UNRATE      3.50    3.50   3.50       0.0\n",
       "2020-01-14 13:30:00     CPI      0.30    0.20   0.30      -0.1\n",
       "2020-01-29 19:00:00    INTR      1.75    1.75   1.75       0.0\n",
       "2020-01-30 13:30:00     GDP      2.00    2.10   2.10       0.1\n",
       "2020-01-31 13:30:00     PCE      0.20    0.30   0.20       0.1\n",
       "...                     ...       ...     ...    ...       ...\n",
       "2025-01-29 19:00:00    INTR      4.50    4.50   4.50       0.0\n",
       "2025-01-30 13:30:00     GDP      2.60    2.30   3.10      -0.3\n",
       "2025-01-31 13:30:00     PCE      0.30    0.30   0.10       0.0\n",
       "2025-02-07 13:30:00  UNRATE      4.10    4.10   4.10       0.0\n",
       "2025-02-12 13:30:00     CPI      0.30    0.50   0.40       0.2\n",
       "\n",
       "[311 rows x 5 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macroeconomics DataFrame\n",
    "macro_df = clean_macro_dataframe(\n",
    "                surprise_calculation(\n",
    "                    convert_percentage_to_numeric(\n",
    "                        standardize_datetime_format(\n",
    "                            handle_missing_values(macro_df)\n",
    "                        )\n",
    "                   )\n",
    "                )\n",
    "           )\n",
    "\n",
    "macro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772df5e",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f502b9",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Create final df with all Pairs and Macro events</span>\n",
    "1. Fetch all data for the past 2 years for each pair 'fetch_and_combine_fx_data(macro_df, pair)'\n",
    "2. Merge the datasets \n",
    "3. Fetch only data with events (-5 +10 from the event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc72b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_combine_fx_data(macro_df, pair):\n",
    "    \n",
    "    filtered_macro_df = macro_df[macro_df.index >= \"2023-03-10\"].copy()\n",
    "    \n",
    "    # Get index values to list\n",
    "    macro_dates_list = filtered_macro_df.index.strftime(\"%Y-%m-%d\").tolist()\n",
    "    \n",
    "    # Initialize empty DataFrame\n",
    "    data_df = pd.DataFrame()  \n",
    "\n",
    "    for i, date in enumerate(macro_dates_list):\n",
    "        fx_data = calculate_volatility(polygon_get_fx_data(pair, \"minute\", date, date))\n",
    "        \n",
    "        # Add pair symbol as a prefix to columns (excluding Datetime)\n",
    "        fx_data = fx_data.rename(columns={col: f\"{pair}_{col}\" for col in fx_data.columns if col != \"Datetime\"})\n",
    "        \n",
    "        # Append the retrieved data to the main DataFrame\n",
    "        data_df = pd.concat([data_df, fx_data])\n",
    "\n",
    "        # Implement sleep logic for API limitations\n",
    "        if (i + 1) % 5 == 0:  \n",
    "            time.sleep(70)\n",
    "        else:\n",
    "            time.sleep(2) \n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0451606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_fx_data(fx_data, macro_df):\n",
    "    extracted_data = []\n",
    "\n",
    "    for event_time in macro_df.index:\n",
    "        start_time = event_time - pd.Timedelta(minutes=5)\n",
    "        end_time = event_time + pd.Timedelta(minutes=10)\n",
    "\n",
    "        # Check if any timestamps in the range exist in fx_data\n",
    "        available_times = fx_data.index[(fx_data.index >= start_time) & (fx_data.index <= end_time)]\n",
    "\n",
    "        if available_times.empty:  \n",
    "            continue  # Skip if no matching timestamps exist\n",
    "\n",
    "        filtered_fx = fx_data.loc[available_times].copy()\n",
    "\n",
    "        # Add event details from macro_df\n",
    "        if event_time in macro_df.index:\n",
    "            filtered_fx[\"Ticker\"] = macro_df.loc[event_time, \"Ticker\"]\n",
    "            filtered_fx[\"Expected\"] = macro_df.loc[event_time, \"Expected\"]\n",
    "            filtered_fx[\"Actual\"] = macro_df.loc[event_time, \"Actual\"]\n",
    "            filtered_fx[\"Prior\"] = macro_df.loc[event_time, \"Prior\"]\n",
    "            filtered_fx[\"Surprise\"] = macro_df.loc[event_time, \"Surprise\"]\n",
    "\n",
    "        extracted_data.append(filtered_fx)\n",
    "\n",
    "    # Set Datetime index\n",
    "    final_df = pd.concat(extracted_data).reset_index()\n",
    "    final_df = final_df.rename(columns={\"index\": \"Datetime\"}).set_index(\"Datetime\")\n",
    "    # Drop duplicates if they exist\n",
    "    final_df = final_df[~final_df.index.duplicated(keep=\"first\")]\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f132a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eur = fetch_and_combine_fx_data(macro_df, \"USDEUR\")\n",
    "# gbp = fetch_and_combine_fx_data(macro_df, \"USDGBP\")\n",
    "# cnh = fetch_and_combine_fx_data(macro_df, \"USDCNH\")\n",
    "\n",
    "eur = pd.read_csv(\"USDEUR_data.csv\")\n",
    "gbp = pd.read_csv(\"USDGBP_data.csv\")\n",
    "cnh = pd.read_csv(\"USDCNH_data.csv\")\n",
    "\n",
    "for df in [eur, gbp, cnh]:\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'], dayfirst=True)\n",
    "    df['Datetime'] = df['Datetime'].dt.strftime(\"%d/%m/%Y %H:%M\")\n",
    "    df.set_index('Datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e3a5e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge all three dataframes on 'Datetime' index, keeping only matching timestamps\n",
    "merged_df = eur.merge(gbp, left_index=True, right_index=True, how=\"inner\") \\\n",
    "               .merge(cnh, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "# Ensure the index is in datetime format\n",
    "merged_df.index = pd.to_datetime(merged_df.index, format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "# Sort the merged DataFrame by 'Datetime' index\n",
    "merged_df.sort_index(inplace=True)\n",
    "\n",
    "# all data for 126 events from March of 2023 until February 2025\n",
    "data = extract_relevant_fx_data(merged_df, macro_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75199621",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c2ea7",
   "metadata": {},
   "source": [
    "## 1. Volatility Analysis on Pairs\n",
    "1. Compute volatility per pair symbol on events (e.g., USD/GBP, USD/EURO, USD/CNH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7bdf74bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Expected</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prior</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01 12:30:00</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01 13:45:00</th>\n",
       "      <td>PMI</td>\n",
       "      <td>47.80</td>\n",
       "      <td>48.50</td>\n",
       "      <td>47.30</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-07 19:00:00</th>\n",
       "      <td>INTR</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-13 13:30:00</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-27 13:30:00</th>\n",
       "      <td>GDP</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-27 15:00:00</th>\n",
       "      <td>PCE</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-02 14:45:00</th>\n",
       "      <td>PMI</td>\n",
       "      <td>48.80</td>\n",
       "      <td>49.70</td>\n",
       "      <td>48.50</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-06 13:30:00</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-11 13:30:00</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-18 19:00:00</th>\n",
       "      <td>INTR</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-19 13:30:00</th>\n",
       "      <td>GDP</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-20 13:30:00</th>\n",
       "      <td>PCE</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-02 14:45:00</th>\n",
       "      <td>PMI</td>\n",
       "      <td>48.30</td>\n",
       "      <td>49.40</td>\n",
       "      <td>49.70</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-10 13:30:00</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-15 13:30:00</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-29 19:00:00</th>\n",
       "      <td>INTR</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-30 13:30:00</th>\n",
       "      <td>GDP</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-31 13:30:00</th>\n",
       "      <td>PCE</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-07 13:30:00</th>\n",
       "      <td>UNRATE</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-12 13:30:00</th>\n",
       "      <td>CPI</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Ticker  Expected  Actual  Prior  Surprise\n",
       "Datetime                                                      \n",
       "2024-11-01 12:30:00  UNRATE      4.10    4.10   4.10       0.0\n",
       "2024-11-01 13:45:00     PMI     47.80   48.50  47.30       0.7\n",
       "2024-11-07 19:00:00    INTR      4.75    4.75   5.00       0.0\n",
       "2024-11-13 13:30:00     CPI      0.20    0.20   0.20       0.0\n",
       "2024-11-27 13:30:00     GDP      2.80    2.80   2.80       0.0\n",
       "2024-11-27 15:00:00     PCE      0.20    0.20   0.20       0.0\n",
       "2024-12-02 14:45:00     PMI     48.80   49.70  48.50       0.9\n",
       "2024-12-06 13:30:00  UNRATE      4.10    4.20   4.10       0.1\n",
       "2024-12-11 13:30:00     CPI      0.30    0.30   0.20       0.0\n",
       "2024-12-18 19:00:00    INTR      4.50    4.50   4.75       0.0\n",
       "2024-12-19 13:30:00     GDP      2.80    3.10   2.80       0.3\n",
       "2024-12-20 13:30:00     PCE      0.20    0.10   0.20      -0.1\n",
       "2025-01-02 14:45:00     PMI     48.30   49.40  49.70       1.1\n",
       "2025-01-10 13:30:00  UNRATE      4.20    4.10   4.20      -0.1\n",
       "2025-01-15 13:30:00     CPI      0.40    0.40   0.30       0.0\n",
       "2025-01-29 19:00:00    INTR      4.50    4.50   4.50       0.0\n",
       "2025-01-30 13:30:00     GDP      2.60    2.30   3.10      -0.3\n",
       "2025-01-31 13:30:00     PCE      0.30    0.30   0.10       0.0\n",
       "2025-02-07 13:30:00  UNRATE      4.10    4.10   4.10       0.0\n",
       "2025-02-12 13:30:00     CPI      0.30    0.50   0.40       0.2"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dates = {\"GDP\": \"2024-12-19\", \n",
    "               \"PCE\": \"2024-12-20\", \n",
    "               \"PMI\": \"2025-01-02\",\n",
    "               \"UNRATE\": \"2025-01-10\", \n",
    "               \"INTR\": \"2025-01-29\", \n",
    "               \"CPI\": \"2025-02-12\"\n",
    "               }\n",
    "pairs = [\"USDEUR\", \"USDCNH\", \"USDGBP\"]\n",
    "\n",
    "api_request_limitation_rest = 1\n",
    "\n",
    "for event, date in event_dates.items():\n",
    "    for pair in pairs:\n",
    "        api_request_limitation_rest += 1\n",
    "        if api_request_limitation_rest % 5:\n",
    "            time.sleep(70)\n",
    "        df = calculate_volatility(polygon_get_fx_data(pair, \"minute\", date, date))\n",
    "        df['Volatility'] = pd.to_numeric(df['Volatility'], errors='coerce')\n",
    "        df['Rolling_Volatility'] = df['Volatility'].rolling(window=16, min_periods=1).sum()\n",
    "        end_time = df['Rolling_Volatility'].idxmax()\n",
    "        start_time = end_time - pd.Timedelta(minutes=16)\n",
    "        print(f\"Most volatile timeframe for {pair} during {event} on {date}: {start_time} - {end_time}\")\n",
    "        \n",
    "# df = calculate_volatility(polygon_get_fx_data(\"USDEUR\", \"minute\", \"2025-02-12\", \"2025-02-12\"))\n",
    "\n",
    "# df['Volatility'] = pd.to_numeric(df['Volatility'], errors='coerce')\n",
    "\n",
    "# # Rolling window calculation for 20-minute periods\n",
    "# df['Rolling_Volatility'] = df['Volatility'].rolling(window=16, min_periods=1).sum()\n",
    "\n",
    "# # Find the time period with the highest volatility\n",
    "# end_time = df['Rolling_Volatility'].idxmax()\n",
    "# start_time = end_time - pd.Timedelta(minutes=16)\n",
    "\n",
    "# # Plot specific timeframe\n",
    "# df = df.between_time('13:25', '13:45')\n",
    "# plot_time_series(df, \"Volatility_Multiplier\")\n",
    "\n",
    "# # Display results\n",
    "# print(f\"Most volatile time:\\n {start_time} - {end_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9023ca",
   "metadata": {},
   "source": [
    "## 2. Economic Data Seasonality report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3aa037",
   "metadata": {},
   "source": [
    "## 3.  Economic Announcment Selection - Feature Importance / Importance of Macro events (feature importance on movement based on price change and volatility)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa776ea",
   "metadata": {},
   "source": [
    "1. Do some feature importance to keep the major macro data releases and do detailed analysis on these ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b857b36",
   "metadata": {},
   "source": [
    "## 4. Responses to CPI, IR, GDP, Unemployment Rate (R2 before appendix) - Jump (R4 p32) - Volatility Increase on each event table - Data Release Trend: Before/On/After"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92404046",
   "metadata": {},
   "source": [
    "1. Charts\n",
    "2. Table with all info for CPI, IR, GDP, UR, JUMP, Vol increase from avg for all pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a2fe6",
   "metadata": {},
   "source": [
    "## 5. Prior vs Now (volatility and importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26980aec",
   "metadata": {},
   "source": [
    "1. Bar chart showing importance % in the past for the price movement for all events (x axis) on DXY:\n",
    "    * For now pick average of 1 or 2 last years of data (e.g., 2023-2024)\n",
    "    * For past pick average of 1 or 2 years in the past data (e.g., 2018-2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a74b7",
   "metadata": {},
   "source": [
    "## 6. Analysis of High Volume Intraday on Data Releases\n",
    "1. Find out in a way how much to keep out of each day (e.g., 10 minutes before and 10 minutes after the event)\n",
    "2. Volatility within -5m/-1m, 1m, 1m-5m, >5m (% to understand when the market moves the most)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20447f05",
   "metadata": {},
   "source": [
    "## 7. Correlation of USD pairs and DXY price movements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24ecae",
   "metadata": {},
   "source": [
    "1. Correlation heatmap\n",
    "2. Identify which one moves first if not all together to see for arbritrage opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc59f7",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
